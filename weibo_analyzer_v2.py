# -*- coding: utf-8 -*-
"""
å¾®åšçƒ­æœäº§å“åˆ›æ„åˆ†æå·¥å…· v2.1 (å®Œå…¨ç‹¬ç«‹ç‰ˆæœ¬)
åŠŸèƒ½ï¼šè‡ªåŠ¨æŠ“å–å¾®åšçƒ­æœï¼Œä½¿ç”¨æ™ºè°±AIåˆ†æäº§å“åˆ›æ„ï¼Œç”ŸæˆHTMLæŠ¥å‘Š
"""

import sys
import io
import os
import json
import re
import time
import random
from datetime import datetime
from pathlib import Path

sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

import requests
from bs4 import BeautifulSoup

# Claude Agent SDK
try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False
    print("âš ï¸  è­¦å‘Š: anthropicåŒ…æœªå®‰è£…")
    print("   å®‰è£…å‘½ä»¤: pip install anthropic")

# ============================================================================
# é…ç½®åŠ è½½
# ============================================================================

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = Path(__file__).parent / "config.json"
    if config_path.exists():
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass

    return {
        "weibo_api": {
            "url": "https://apis.tianapi.com/weibohot/index",
            "key": os.environ.get("TIANAPI_KEY", "")
        },
        "analysis": {
            "default_count": 10,
            "enable_ai_analysis": True,
            "enable_web_search": True,
            "max_concurrent_searches": 5,
            "use_claude_sdk": ANTHROPIC_AVAILABLE
        },
        "output": {
            "directory": "output",
            "auto_open": False
        }
    }

CONFIG = load_config()

# ============================================================================
# å¾®åšçƒ­æœAPIè°ƒç”¨
# ============================================================================

def fetch_weibo_hot(count=10):
    """è·å–å¾®åšçƒ­æœæ¦œå•ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
    url = CONFIG["weibo_api"]["url"]
    params = {
        "key": CONFIG["weibo_api"]["key"],
        "num": count
    }

    print(f"\n{'='*55}")
    print(f"   å¾®åšçƒ­æœäº§å“åˆ›æ„åˆ†æå·¥å…· v2.1 (æ™ºè°±AIå¢å¼ºç‰ˆ)")
    print(f"{'='*55}")
    print(f"\næ­£åœ¨è·å–å¾®åšçƒ­æœTOP {count}...")

    max_retries = 3
    for attempt in range(max_retries):
        try:
            print(f"  å°è¯•ç¬¬ {attempt + 1}/{max_retries} æ¬¡è¯·æ±‚...")
            response = requests.get(url, params=params, timeout=30)
            response.encoding = 'utf-8'

            if response.status_code == 200:
                data = response.json()
                if data.get("code") == 200:
                    hot_list = data.get("result", {}).get("list", [])
                    hot_list = hot_list[:count]
                    print(f"âœ“ è·å–æˆåŠŸï¼å…± {len(hot_list)} æ¡çƒ­æœ\n")
                    return hot_list
                else:
                    print(f"  APIè¿”å›é”™è¯¯: {data.get('msg', 'æœªçŸ¥é”™è¯¯')}")
            else:
                print(f"  HTTPé”™è¯¯: {response.status_code}")

            if attempt < max_retries - 1:
                print(f"  ç­‰å¾…2ç§’åé‡è¯•...")
                time.sleep(2)
            else:
                return get_backup_hot_list(count)

        except requests.exceptions.Timeout:
            print(f"  è¯·æ±‚è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
            if attempt < max_retries - 1:
                print(f"  ç­‰å¾…2ç§’åé‡è¯•...")
                time.sleep(2)
            else:
                print(f"  æ‰€æœ‰é‡è¯•å‡å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®")
                return get_backup_hot_list(count)
        except Exception as e:
            print(f"  è¯·æ±‚å¼‚å¸¸: {str(e)[:50]}")
            if attempt < max_retries - 1:
                print(f"  ç­‰å¾…2ç§’åé‡è¯•...")
                time.sleep(2)
            else:
                print(f"  æ‰€æœ‰é‡è¯•å‡å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®")
                return get_backup_hot_list(count)

    return get_backup_hot_list(count)

def get_backup_hot_list(count=10):
    """å¤‡ç”¨çƒ­æœåˆ—è¡¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    print("ä½¿ç”¨å¤‡ç”¨çƒ­æœæ•°æ®...\n")
    return [
        {"hotWord": f"AIæŠ€æœ¯çªç ´{i}", "hotRank": i, "hotScore": 1000000 - i * 10000}
        for i in range(1, count + 1)
    ]

# ============================================================================
# Webæœç´¢åŠŸèƒ½
# ============================================================================

def web_search_topic(topic, max_results=3):
    """å¯¹çƒ­æœè¯é¢˜è¿›è¡Œwebæœç´¢"""
    if not CONFIG["analysis"].get("enable_web_search", True):
        return []

    try:
        search_query = f"{topic} æ–°é—» èƒŒæ™¯"
        encoded_query = requests.utils.quote(search_query)
        search_url = f"https://www.baidu.com/s?wd={encoded_query}"

        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }

        time.sleep(0.5)
        response = requests.get(search_url, headers=headers, timeout=10)
        response.encoding = 'utf-8'

        soup = BeautifulSoup(response.text, 'html.parser')
        results = []

        # å°è¯•å¤šç§é€‰æ‹©å™¨
        for item in soup.select('.result')[:max_results]:
            try:
                title_elem = item.select_one('h3 a')
                if title_elem:
                    title = title_elem.get_text(strip=True)
                    if title and len(title) > 5:
                        results.append({
                            "title": title[:100],
                            "url": title_elem.get('href', '')
                        })
            except:
                continue

        return results

    except Exception as e:
        print(f"  [æœç´¢è·³è¿‡] {str(e)[:30]}")
        return []

# ============================================================================
# æ™ºè°±AIäº§å“åˆ†æå™¨
# ============================================================================

class ZhipuProductAnalyzer:
    """ä½¿ç”¨æ™ºè°±AIè¿›è¡Œäº§å“åˆ›æ„åˆ†æ"""

    def __init__(self):
        if not ANTHROPIC_AVAILABLE:
            raise ImportError("anthropicåŒ…æœªå®‰è£…")

        api_key = os.environ.get("ANTHROPIC_API_KEY")
        if not api_key:
            raise ValueError("ANTHROPIC_API_KEYç¯å¢ƒå˜é‡æœªè®¾ç½®")

        custom_api_url = os.environ.get("CUSTOM_API_URL")
        if custom_api_url:
            self.client = anthropic.Anthropic(api_key=api_key, base_url=custom_api_url)
            print(f"âœ“ ä½¿ç”¨è‡ªå®šä¹‰APIç«¯ç‚¹")
        else:
            self.client = anthropic.Anthropic(api_key=api_key)

        self.model = os.environ.get("CUSTOM_MODEL_ID", "glm-4.7")
        print(f"âœ“ AIåˆ†æå™¨å·²åˆå§‹åŒ– (æ¨¡å‹: {self.model})")

    def analyze_product_idea(self, topic: str, search_results: list) -> dict:
        """ä½¿ç”¨æ™ºè°±AIåˆ†æäº§å“åˆ›æ„"""

        context = self._build_context(topic, search_results)

        prompt = f"""ä½ æ˜¯äº§å“åˆ›æ–°ä¸“å®¶ã€‚åŸºäºçƒ­æœè¯é¢˜è¿›è¡Œäº§å“åˆ›æ„åˆ†æï¼š

çƒ­æœè¯é¢˜: {topic}

{self._format_search_results(search_results)}

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼ˆç›´æ¥è¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼‰ï¼š
{{
    "name": "äº§å“åç§°ï¼ˆä¸è¶…è¿‡15å­—ï¼‰",
    "core_features": [
        "åŠŸèƒ½1 - æè¿°",
        "åŠŸèƒ½2 - æè¿°",
        "åŠŸèƒ½3 - æè¿°",
        "åŠŸèƒ½4 - æè¿°",
        "åŠŸèƒ½5 - æè¿°"
    ],
    "market_pain_points": [
        "ç—›ç‚¹1",
        "ç—›ç‚¹2",
        "ç—›ç‚¹3",
        "ç—›ç‚¹4",
        "ç—›ç‚¹5"
    ],
    "target_users": "ç›®æ ‡ç”¨æˆ·æè¿°ï¼ˆ50å­—å†…ï¼‰",
    "innovation_points": [
        "åˆ›æ–°ç‚¹1",
        "åˆ›æ–°ç‚¹2",
        "åˆ›æ–°ç‚¹3"
    ],
    "market_potential": {{
        "market_size": "å¸‚åœºè§„æ¨¡",
        "growth_stage": "å¢é•¿é˜¶æ®µ",
        "competitive_advantage": "ä¼˜åŠ¿",
        "revenue_model": "å•†ä¸šæ¨¡å¼"
    }},
    "scores": {{
        "innovation": åˆ›æ–°æ€§(15-30),
        "pain_point": ç—›ç‚¹æ´å¯Ÿ(15-25),
        "potential": æ½œåŠ›ç©ºé—´(10-15),
        "social": ç¤¾äº¤å±æ€§(5-10),
        "practicality": å®ç”¨æ€§(5-10),
        "feasibility": å¯è¡Œæ€§(5-10)
    }}
}}

è¯·ç¡®ä¿åˆ†æå…·ä½“ã€æœ‰æ´å¯ŸåŠ›ï¼Œé¿å…å¥—è¯ã€‚"""

        try:
            response = self.client.messages.create(
                model=self.model,
                max_tokens=2000,
                messages=[{"role": "user", "content": prompt}]
            )

            result_text = response.content[0].text

            # æ¸…ç†markdownæ ‡è®°
            if result_text.startswith("```json"):
                result_text = result_text[7:]
            if result_text.startswith("```"):
                result_text = result_text[3:]
            if result_text.endswith("```"):
                result_text = result_text[:-3]
            result_text = result_text.strip()

            analysis = json.loads(result_text)

            # è®¡ç®—æ€»åˆ†
            scores = analysis["scores"]
            interest_score = scores["innovation"] + scores["pain_point"] + scores["potential"] + scores["social"]
            utility_score = scores["practicality"] + scores["feasibility"]
            scores["total"] = round(interest_score + utility_score, 1)
            scores["interest_score"] = interest_score
            scores["utility_score"] = utility_score

            print(f"  âœ“ AIåˆ†æå®Œæˆ: {analysis['name'][:20]} (è¯„åˆ†: {scores['total']})")

            return analysis

        except json.JSONDecodeError as e:
            print(f"  âœ— JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨è§„åˆ™å¼•æ“")
            return self._rule_based_analysis(topic, search_results)
        except Exception as e:
            print(f"  âœ— AIè°ƒç”¨å¤±è´¥: {str(e)[:30]}ï¼Œä½¿ç”¨è§„åˆ™å¼•æ“")
            return self._rule_based_analysis(topic, search_results)

    def _build_context(self, topic: str, search_results: list) -> str:
        """æ„å»ºåˆ†æä¸Šä¸‹æ–‡"""
        context = f"çƒ­æœè¯é¢˜: {topic}\n"
        if search_results:
            context += "\nç›¸å…³æ–°é—»:\n"
            for r in search_results[:3]:
                context += f"  - {r['title']}\n"
        return context

    def _format_search_results(self, search_results: list) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœ"""
        if not search_results:
            return "ï¼ˆæš‚æ— æœç´¢ç»“æœï¼‰"
        return "\n".join([f"- {r['title']}" for r in search_results[:3]])

    def _rule_based_analysis(self, topic: str, search_results: list) -> dict:
        """è§„åˆ™å¼•æ“åˆ†æï¼ˆAIå¤±è´¥æ—¶é™çº§ï¼‰"""
        random.seed(hash(topic))

        return {
            "name": f"ã€Œ{topic[:8]}ã€æ™ºèƒ½åŠ©æ‰‹",
            "core_features": [
                f"å®æ—¶è¿½è¸ª'{topic}'ç›¸å…³åŠ¨æ€",
                "AIæ™ºèƒ½åˆ†æä¸æ¨è",
                "ä¸ªæ€§åŒ–å†…å®¹å®šåˆ¶",
                "ç¤¾äº¤äº’åŠ¨åˆ†äº«",
                "æ•°æ®å¯è§†åŒ–å±•ç¤º"
            ],
            "market_pain_points": [
                f"å…³äº'{topic}'çš„ä¿¡æ¯åˆ†æ•£",
                "ç¼ºä¹ä¸“ä¸šæ·±åº¦åˆ†æ",
                "ä¸ªæ€§åŒ–æ¨èä¸è¶³",
                "äº’åŠ¨ä½“éªŒå·®",
                "æ•°æ®ä¸ç›´è§‚"
            ],
            "target_users": f"å…³æ³¨'{topic}'çš„ç”¨æˆ·ç¾¤ä½“",
            "innovation_points": [
                f"é’ˆå¯¹'{topic}'çš„ä¸“ä¸šåˆ†æ",
                "AIæ™ºèƒ½æ¨è",
                "å¤šç»´åº¦æ•°æ®èåˆ",
                "å®æ—¶è¿½è¸ª",
                "ç¤¾äº¤åŒ–åä½œ"
            ],
            "market_potential": {
                "market_size": f"åŸºäº'{topic}'çš„å‚ç›´å¸‚åœº",
                "growth_stage": "æˆé•¿æœŸ",
                "competitive_advantage": "ä¸“ä¸šå£å’",
                "revenue_model": "ä¼šå‘˜+å¢å€¼æœåŠ¡"
            },
            "scores": {
                "innovation": random.randint(15, 30),
                "pain_point": random.randint(15, 25),
                "potential": random.randint(10, 15),
                "social": random.randint(5, 10),
                "practicality": random.randint(5, 10),
                "feasibility": random.randint(5, 10),
                "total": 0,
                "interest_score": 0,
                "utility_score": 0
            }
        }

# ============================================================================
# ä¸»æµç¨‹
# ============================================================================

def main(count=None):
    """ä¸»å‡½æ•°"""
    if count is None:
        count = CONFIG["analysis"]["default_count"]

    # åˆå§‹åŒ–AIåˆ†æå™¨
    try:
        analyzer = ZhipuProductAnalyzer()
        use_ai = True
    except Exception as e:
        print(f"âš ï¸ AIåˆå§‹åŒ–å¤±è´¥: {e}")
        print("å°†ä½¿ç”¨è§„åˆ™å¼•æ“æ¨¡å¼")
        use_ai = False

    # 1. è·å–å¾®åšçƒ­æœ
    hot_list = fetch_weibo_hot(count)
    if not hot_list:
        print("æœªèƒ½è·å–çƒ­æœæ•°æ®")
        return None

    # 2. åˆ†ææ¯ä¸ªçƒ­æœ
    print("æ­£åœ¨åˆ†æçƒ­æœè¯é¢˜...")
    hot_topics_with_analysis = []

    for i, hot in enumerate(hot_list, 1):
        topic = hot.get("hotword", hot.get("hotWord", ""))
        rank = i

        print(f"  [{i}/{len(hot_list)}] åˆ†æ: {topic}")

        # Webæœç´¢ï¼ˆå¯é€‰ï¼‰
        search_results = []
        if CONFIG["analysis"].get("enable_web_search"):
            try:
                search_results = web_search_topic(topic)
            except:
                pass

        # AIåˆ†ææˆ–è§„åˆ™å¼•æ“
        if use_ai:
            try:
                analysis = analyzer.analyze_product_idea(topic, search_results)
            except Exception as e:
                print(f"  âœ— åˆ†æå¤±è´¥: {e}")
                analysis = analyzer._rule_based_analysis(topic, search_results)
        else:
            analysis = analyzer._rule_based_analysis(topic, search_results)

        hot_topics_with_analysis.append({
            "topic": topic,
            "rank": rank,
            "hot_score": hot.get("hotScore", 0),
            "search_results": search_results,
            "analysis": analysis
        })

        print()

    # 3. ç”ŸæˆHTMLæŠ¥å‘Š
    print("æ­£åœ¨ç”ŸæˆHTMLæŠ¥å‘Š...")
    generate_html_report(hot_topics_with_analysis)

    # 4. è¾“å‡ºæ‘˜è¦
    print_summary(hot_topics_with_analysis)

    return True

def generate_html_report(hot_topics_with_analysis):
    """ç”ŸæˆHTMLæŠ¥å‘Š"""
    today = datetime.now()
    date_str = today.strftime("%Y%m%d")
    timestamp = today.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")

    # æŒ‰è¯„åˆ†æ’åº
    sorted_topics = sorted(
        hot_topics_with_analysis,
        key=lambda x: x['analysis']['scores']['total'],
        reverse=True
    )

    # ç»Ÿè®¡
    excellent = sum(1 for t in sorted_topics if t['analysis']['scores']['total'] >= 80)
    good = sum(1 for t in sorted_topics if 60 <= t['analysis']['scores']['total'] < 80)
    average = sum(1 for t in sorted_topics if t['analysis']['scores']['total'] < 60)

    # ç”Ÿæˆæ–‡ä»¶åºå·
    output_dir = Path(__file__).parent / CONFIG["output"]["directory"]
    output_dir.mkdir(exist_ok=True)

    existing_files = list(output_dir.glob(f"weibo_hot_{date_str}_*.html"))
    if existing_files:
        numbers = []
        for f in existing_files:
            match = re.search(rf'weibo_hot_{date_str}_(\d+)\.html', f.name)
            if match:
                numbers.append(int(match.group(1)))
        file_number = max(numbers) + 1 if numbers else 1
    else:
        file_number = 1

    filename = f"weibo_hot_{date_str}_{file_number}.html"

    # ç”ŸæˆHTML
    html = f'''<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>å¾®åšçƒ­æœäº§å“åˆ›æ„åˆ†æ - {date_str}</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
            min-height: 100vh;
            padding: 20px;
            line-height: 1.6;
        }}
        .container {{ max-width: 900px; margin: 0 auto; }}
        header {{ text-align: center; margin-bottom: 30px; }}
        h1 {{
            font-size: 2em;
            background: linear-gradient(90deg, #ff6b6b, #feca57, #48dbfb);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            margin-bottom: 10px;
        }}
        .subtitle {{ color: #94a3b8; font-size: 0.9em; }}
        .stats {{
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-top: 20px;
            flex-wrap: wrap;
        }}
        .stat-item {{
            background: rgba(255,255,255,0.1);
            padding: 15px 20px;
            border-radius: 10px;
            text-align: center;
        }}
        .stat-value {{ font-size: 1.5em; font-weight: bold; }}
        .stat-label {{ color: #94a3b8; font-size: 0.8em; }}
        .excellent {{ color: #ffd700; }}
        .good {{ color: #48dbfb; }}
        .average {{ color: #a0aec0; }}
        .topic-card {{
            background: white;
            border-radius: 15px;
            padding: 25px;
            margin-bottom: 20px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        }}
        .topic-header {{
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 20px;
            padding-bottom: 15px;
            border-bottom: 2px solid #f0f0f0;
        }}
        .topic-title {{ font-size: 1.4em; font-weight: bold; }}
        .score {{ font-size: 2.5em; font-weight: bold; color: #16a34a; }}
        .section {{ margin: 15px 0; }}
        .section-title {{ font-weight: bold; margin-bottom: 10px; color: #333; }}
        .feature-list {{ list-style: none; }}
        .feature-list li {{
            padding: 8px 0;
            border-bottom: 1px solid #f5f5f5;
        }}
        .tag {{
            display: inline-block;
            background: #22c55e;
            color: white;
            padding: 4px 12px;
            border-radius: 20px;
            font-size: 0.8em;
            margin-left: 10px;
        }}
        .product-details {{
            background: #fefce8;
            padding: 20px;
            border-radius: 10px;
            margin-top: 15px;
        }}
        .footer {{
            text-align: center;
            margin-top: 30px;
            color: #64748b;
            font-size: 0.8em;
        }}
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>å¾®åšçƒ­æœäº§å“åˆ›æ„åˆ†ææŠ¥å‘Š</h1>
            <p class="subtitle">åŸºäºçƒ­æœè¯é¢˜çš„äº§å“åˆ›æ–°æœºä¼šæŒ–æ˜</p>
            <p class="subtitle">ç”Ÿæˆæ—¶é—´: {timestamp}</p>

            <div class="stats">
                <div class="stat-item">
                    <div class="stat-value">{len(sorted_topics)}</div>
                    <div class="stat-label">åˆ†æçƒ­ç‚¹</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value excellent">{excellent}</div>
                    <div class="stat-label">ä¼˜ç§€åˆ›æ„ (â‰¥80åˆ†)</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value good">{good}</div>
                    <div class="stat-label">è‰¯å¥½åˆ›æ„ (60-80åˆ†)</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value average">{average}</div>
                    <div class="stat-label">ä¸€èˆ¬åˆ›æ„ (<60åˆ†)</div>
                </div>
            </div>
        </header>
'''

    for topic_data in sorted_topics:
        topic = topic_data['topic']
        analysis = topic_data['analysis']
        scores = analysis['scores']

        html += f'''
        <div class="topic-card">
            <div class="topic-header">
                <div>
                    <span class="topic-title">ğŸ”¥ {topic}</span>
                    <span class="tag">çƒ­</span>
                </div>
                <div class="score">{scores['total']}</div>
            </div>

            <div class="product-details">
                <div class="section">
                    <div class="section-title">ğŸ¯ äº§å“åç§°</div>
                    <div>{analysis['name']}</div>
                </div>

                <div class="section">
                    <div class="section-title">âš™ï¸ æ ¸å¿ƒåŠŸèƒ½</div>
                    <ul class="feature-list">
                        {''.join([f'<li>{f}</li>' for f in analysis['core_features'][:5]])}
                    </ul>
                </div>

                <div class="section">
                    <div class="section-title">ğŸ‘¥ ç›®æ ‡ç”¨æˆ·</div>
                    <div>{analysis['target_users']}</div>
                </div>

                <div class="section">
                    <div class="section-title">ğŸ“Š è¯„åˆ†è¯¦æƒ…</div>
                    <div>æœ‰è¶£åº¦: {scores.get('interest_score', 0)}/80åˆ† |
                        æœ‰ç”¨åº¦: {scores.get('utility_score', 0)}/20åˆ† |
                        ç»¼åˆ: {scores['total']}åˆ†</div>
                </div>
            </div>
        </div>
'''

    html += '''
        <div class="footer">
            <p>æ•°æ®æ¥æº: å¾®åšçƒ­æœ | ç”Ÿæˆå·¥å…·: å¾®åšçƒ­æœäº§å“åˆ›æ„åˆ†æ v2.1 (æ™ºè°±AIå¢å¼ºç‰ˆ)</p>
            <p>æœ¬æŠ¥å‘ŠåŸºäºAIåˆ†æç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ</p>
        </div>
    </div>
</body>
</html>'''

    # ä¿å­˜æ–‡ä»¶
    output_path = output_dir / filename
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(html)

    print(f"âœ“ æŠ¥å‘Šå·²ä¿å­˜: {output_path.name}")

def print_summary(hot_topics_with_analysis):
    """è¾“å‡ºåˆ†ææ‘˜è¦"""
    print(f"\n{'='*55}")
    print("   åˆ†æå®Œæˆï¼")
    print(f"{'='*55}")

    sorted_by_score = sorted(
        hot_topics_with_analysis,
        key=lambda x: x['analysis']['scores']['total'],
        reverse=True
    )

    excellent = sum(1 for t in sorted_by_score if t['analysis']['scores']['total'] >= 80)
    good = sum(1 for t in sorted_by_score if 60 <= t['analysis']['scores']['total'] < 80)

    print(f"\nğŸ“Š åˆ†ææ¦‚å†µ:")
    print(f"  - åˆ†æçƒ­ç‚¹: {len(hot_topics_with_analysis)}ä¸ª")
    print(f"  - ä¼˜ç§€åˆ›æ„(â‰¥80åˆ†): {excellent}ä¸ª")
    print(f"  - è‰¯å¥½åˆ›æ„(60-80åˆ†): {good}ä¸ª")

    print(f"\nğŸŒŸ TOP3 ä¼˜ç§€åˆ›æ„:")
    for i, t in enumerate(sorted_by_score[:3], 1):
        print(f"  {i}. {t['analysis']['name'][:30]}")
        print(f"     è¯„åˆ†: {t['analysis']['scores']['total']}åˆ†")

if __name__ == "__main__":
    count = int(sys.argv[1]) if len(sys.argv) > 1 else None
    main(count)
